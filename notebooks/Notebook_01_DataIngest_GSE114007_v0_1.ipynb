{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: GSE114007 Data Ingestion\n",
    "## Kairos Therapeutics ML Prototype V0.1\n",
    "\n",
    "**Author:** Pat Ovando-Roche, PhD  \n",
    "**Date:** 2025-12-26  \n",
    "**Dataset:** GSE114007 - OA vs Healthy knee cartilage RNA-seq  \n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "Download and parse the GSE114007 dataset into:\n",
    "1. `metadata.csv` ‚Äî sample phenotype information\n",
    "2. `raw_source_matrix.csv` ‚Äî expression values as delivered\n",
    "3. `ml_matrix.csv` ‚Äî log-transformed + z-scored for ML\n",
    "\n",
    "### Dataset Summary (from Yin et al. 2023, Aging)\n",
    "- **Tissue:** Human knee articular cartilage\n",
    "- **Comparison:** 18 healthy controls vs 20 OA patients\n",
    "- **Platform:** Illumina RNA-seq (GPL11154, GPL18573)\n",
    "- **Published validation:** AUC = 1.0 for OA classification\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Directory Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created/verified: C:\\Users\\povan\\Kairos_Therapeutics\\data\\raw\\GSE114007\n",
      "‚úÖ Created/verified: C:\\Users\\povan\\Kairos_Therapeutics\\data\\processed\n",
      "‚úÖ Created/verified: C:\\Users\\povan\\Kairos_Therapeutics\\reports\\figures\n",
      "\n",
      "============================================================\n",
      "KAIROS ML PROTOTYPE V0.1 - GSE114007 DATA INGESTION\n",
      "============================================================\n",
      "\n",
      "üìÖ Timestamp: 2025-12-26 16:55:08\n",
      "üêç Python: 3.10.11\n",
      "üì¶ pandas: 2.3.3\n",
      "üì¶ numpy: 1.26.4\n",
      "üìÅ Working directory: C:\\Users\\povan\\Kairos_Therapeutics\\notebooks\n",
      "üìÅ Data will be saved to: C:\\Users\\povan\\Kairos_Therapeutics\\data\\processed\n",
      "\n",
      "‚úÖ Cell 1 complete. Ready for Cell 2.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 1: SETUP AND DIRECTORY CREATION\n",
    "=====================================\n",
    "Creates folder structure and imports required libraries.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import gzip\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# GEO data access\n",
    "import GEOparse\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ============================================\n",
    "# Define paths (relative to notebook location)\n",
    "# ============================================\n",
    "PROJECT_ROOT = Path.cwd().parent  # Go up from notebooks/ to project root\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\" / \"GSE114007\"\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "REPORTS_FIGURES = PROJECT_ROOT / \"reports\" / \"figures\"\n",
    "\n",
    "# Create directories\n",
    "for folder in [DATA_RAW, DATA_PROCESSED, REPORTS_FIGURES]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ Created/verified: {folder}\")\n",
    "\n",
    "# Version info\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KAIROS ML PROTOTYPE V0.1 - GSE114007 DATA INGESTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìÖ Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "print(f\"üì¶ pandas: {pd.__version__}\")\n",
    "print(f\"üì¶ numpy: {np.__version__}\")\n",
    "print(f\"üìÅ Working directory: {Path.cwd()}\")\n",
    "print(f\"üìÅ Data will be saved to: {DATA_PROCESSED}\")\n",
    "print(\"\\n‚úÖ Cell 1 complete. Ready for Cell 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Download GSE114007 Metadata via GEOparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading GSE114007 from GEO...\n",
      "   (This may take 1-3 minutes)\n",
      "\n",
      "‚úÖ Downloaded GSE114007\n",
      "\n",
      "üìä Dataset Summary:\n",
      "   Title: Identification of transcription factors responsible for dysregulated networks in human osteoarthritis cartilage by global gene expression analysis\n",
      "   Type: Expression profiling by high throughput sequencing\n",
      "   Platform(s): ['GPL11154', 'GPL18573']\n",
      "   Number of samples (GSMs): 38\n",
      "\n",
      "üìã Sample IDs: ['GSM3130531', 'GSM3130532', 'GSM3130533', 'GSM3130534', 'GSM3130535']... (showing first 5)\n",
      "\n",
      "‚úÖ Cell 2 complete. Ready for Cell 3.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 2: DOWNLOAD GSE114007 METADATA\n",
    "===================================\n",
    "Uses GEOparse to download the GEO Series and extract sample metadata.\n",
    "Note: For RNA-seq, expression data is typically NOT in GSM.table\n",
    "\"\"\"\n",
    "\n",
    "GEO_ID = \"GSE114007\"\n",
    "\n",
    "print(f\"üì• Downloading {GEO_ID} from GEO...\")\n",
    "print(\"   (This may take 1-3 minutes)\\n\")\n",
    "\n",
    "# Download the GEO series\n",
    "gse = GEOparse.get_GEO(geo=GEO_ID, destdir=str(DATA_RAW), silent=True)\n",
    "\n",
    "print(f\"‚úÖ Downloaded {GEO_ID}\")\n",
    "print(f\"\\nüìä Dataset Summary:\")\n",
    "print(f\"   Title: {gse.metadata.get('title', ['N/A'])[0]}\")\n",
    "print(f\"   Type: {gse.metadata.get('type', ['N/A'])[0]}\")\n",
    "print(f\"   Platform(s): {list(gse.gpls.keys())}\")\n",
    "print(f\"   Number of samples (GSMs): {len(gse.gsms)}\")\n",
    "\n",
    "# List all GSM IDs\n",
    "gsm_ids = list(gse.gsms.keys())\n",
    "print(f\"\\nüìã Sample IDs: {gsm_ids[:5]}... (showing first 5)\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 2 complete. Ready for Cell 3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Extract Sample Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Extracted Metadata Columns:\n",
      "   ['sample_id', 'title', 'source_name', 'organism', 'platform', 'age', 'sex', 'oa_grade']\n",
      "\n",
      "üìä Shape: 38 samples √ó 8 fields\n",
      "\n",
      "üìã First 5 samples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>title</th>\n",
       "      <th>source_name</th>\n",
       "      <th>organism</th>\n",
       "      <th>platform</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>oa_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM3130531</td>\n",
       "      <td>Normal_Cart_2_2</td>\n",
       "      <td>Knee articular cartilage</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>GPL11154</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM3130532</td>\n",
       "      <td>Normal_Cart_3_3</td>\n",
       "      <td>Knee articular cartilage</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>GPL11154</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM3130533</td>\n",
       "      <td>Normal_Cart_4_4</td>\n",
       "      <td>Knee articular cartilage</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>GPL11154</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM3130534</td>\n",
       "      <td>Normal_Cart_5_5</td>\n",
       "      <td>Knee articular cartilage</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>GPL11154</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM3130535</td>\n",
       "      <td>Normal_Cart_6_6</td>\n",
       "      <td>Knee articular cartilage</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>GPL11154</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id            title               source_name      organism  \\\n",
       "0  GSM3130531  Normal_Cart_2_2  Knee articular cartilage  Homo sapiens   \n",
       "1  GSM3130532  Normal_Cart_3_3  Knee articular cartilage  Homo sapiens   \n",
       "2  GSM3130533  Normal_Cart_4_4  Knee articular cartilage  Homo sapiens   \n",
       "3  GSM3130534  Normal_Cart_5_5  Knee articular cartilage  Homo sapiens   \n",
       "4  GSM3130535  Normal_Cart_6_6  Knee articular cartilage  Homo sapiens   \n",
       "\n",
       "   platform age sex oa_grade  \n",
       "0  GPL11154  35   F        1  \n",
       "1  GPL11154  57   F        1  \n",
       "2  GPL11154  26   M        1  \n",
       "3  GPL11154  18   M        1  \n",
       "4  GPL11154  28   M        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Looking for disease/condition columns...\n",
      "   Found: ['oa_grade']\n",
      "\n",
      "   Value counts for 'oa_grade':\n",
      "oa_grade\n",
      "4    20\n",
      "1    18\n",
      "\n",
      "‚úÖ Cell 3 complete. Ready for Cell 4.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 3: EXTRACT SAMPLE METADATA\n",
    "===============================\n",
    "Parse phenotype information from each GSM sample.\n",
    "\"\"\"\n",
    "\n",
    "metadata_records = []\n",
    "\n",
    "for gsm_id, gsm in gse.gsms.items():\n",
    "    record = {\n",
    "        'sample_id': gsm_id,\n",
    "        'title': gsm.metadata.get('title', [''])[0],\n",
    "        'source_name': gsm.metadata.get('source_name_ch1', [''])[0],\n",
    "        'organism': gsm.metadata.get('organism_ch1', [''])[0],\n",
    "        'platform': gsm.metadata.get('platform_id', [''])[0],\n",
    "    }\n",
    "    \n",
    "    # Parse characteristics (contains disease status, age, sex, etc.)\n",
    "    characteristics = gsm.metadata.get('characteristics_ch1', [])\n",
    "    for char in characteristics:\n",
    "        if ':' in char:\n",
    "            key, value = char.split(':', 1)\n",
    "            key = key.strip().lower().replace(' ', '_')\n",
    "            value = value.strip()\n",
    "            record[key] = value\n",
    "    \n",
    "    metadata_records.append(record)\n",
    "\n",
    "# Create DataFrame\n",
    "metadata_df = pd.DataFrame(metadata_records)\n",
    "\n",
    "print(\"üìã Extracted Metadata Columns:\")\n",
    "print(f\"   {list(metadata_df.columns)}\")\n",
    "print(f\"\\nüìä Shape: {metadata_df.shape[0]} samples √ó {metadata_df.shape[1]} fields\")\n",
    "print(\"\\nüìã First 5 samples:\")\n",
    "display(metadata_df.head())\n",
    "\n",
    "# Check for disease status column\n",
    "print(\"\\nüîç Looking for disease/condition columns...\")\n",
    "disease_cols = [col for col in metadata_df.columns if any(x in col.lower() for x in ['disease', 'condition', 'status', 'diagnosis', 'oa', 'osteoarthritis'])]\n",
    "if disease_cols:\n",
    "    print(f\"   Found: {disease_cols}\")\n",
    "    for col in disease_cols:\n",
    "        print(f\"\\n   Value counts for '{col}':\")\n",
    "        print(metadata_df[col].value_counts().to_string())\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è No obvious disease column found. Checking all columns...\")\n",
    "    for col in metadata_df.columns:\n",
    "        unique_vals = metadata_df[col].nunique()\n",
    "        if unique_vals <= 5:\n",
    "            print(f\"\\n   '{col}' ({unique_vals} unique values):\")\n",
    "            print(f\"   {metadata_df[col].value_counts().to_dict()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 3 complete. Ready for Cell 4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Standardize Disease Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found disease column: 'title'\n",
      "   Original values: ['Normal_Cart_2_2' 'Normal_Cart_3_3' 'Normal_Cart_4_4' 'Normal_Cart_5_5'\n",
      " 'Normal_Cart_6_6' 'Normal_Cart_7_3' 'Normal_Cart_9_7' 'Normal_Cart_10_8'\n",
      " 'OA_Cart_1_7' 'OA_Cart_2_8' 'OA_Cart_3_9' 'OA_Cart_4_10' 'OA_Cart_5_5'\n",
      " 'OA_Cart_6_1' 'OA_Cart_7_2' 'OA_Cart_8_5' 'OA_Cart_9_6' 'OA_Cart_10_9'\n",
      " 'normal_01' 'normal_02' 'normal_03' 'normal_04' 'normal_05' 'normal_06'\n",
      " 'normal_07' 'normal_08' 'normal_09' 'normal_10' 'OA_01' 'OA_02' 'OA_03'\n",
      " 'OA_04' 'OA_05' 'OA_06' 'OA_07' 'OA_08' 'OA_09' 'OA_10']\n",
      "\n",
      "üìä Standardized condition counts:\n",
      "condition\n",
      "OA         20\n",
      "Control    18\n",
      "\n",
      "‚úÖ Sample counts match expected (18 Control, 20 OA)\n",
      "\n",
      "‚úÖ Cell 4 complete. Ready for Cell 5.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 4: STANDARDIZE DISEASE LABELS\n",
    "==================================\n",
    "Create a clean 'condition' column with values: 'OA' or 'Control'\n",
    "\"\"\"\n",
    "\n",
    "# Identify the disease column (may vary in naming)\n",
    "# Common names: 'disease_state', 'disease', 'diagnosis', 'tissue'\n",
    "\n",
    "def find_disease_column(df):\n",
    "    \"\"\"Find the column containing disease/condition information.\"\"\"\n",
    "    candidates = ['disease_state', 'disease', 'diagnosis', 'condition', \n",
    "                  'disease_status', 'phenotype', 'group']\n",
    "    \n",
    "    for col in candidates:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    \n",
    "    # Search by content\n",
    "    for col in df.columns:\n",
    "        values = df[col].str.lower().unique()\n",
    "        if any('oa' in str(v) or 'osteoarthritis' in str(v) or 'control' in str(v) \n",
    "               or 'normal' in str(v) or 'healthy' in str(v) for v in values):\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "disease_col = find_disease_column(metadata_df)\n",
    "\n",
    "if disease_col:\n",
    "    print(f\"‚úÖ Found disease column: '{disease_col}'\")\n",
    "    print(f\"   Original values: {metadata_df[disease_col].unique()}\")\n",
    "    \n",
    "    # Standardize to 'OA' and 'Control'\n",
    "    def standardize_condition(val):\n",
    "        val_lower = str(val).lower()\n",
    "        if any(x in val_lower for x in ['oa', 'osteoarthritis', 'disease', 'patient']):\n",
    "            return 'OA'\n",
    "        elif any(x in val_lower for x in ['control', 'normal', 'healthy', 'non-oa']):\n",
    "            return 'Control'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    \n",
    "    metadata_df['condition'] = metadata_df[disease_col].apply(standardize_condition)\n",
    "    \n",
    "    print(f\"\\nüìä Standardized condition counts:\")\n",
    "    condition_counts = metadata_df['condition'].value_counts()\n",
    "    print(condition_counts.to_string())\n",
    "    \n",
    "    # Verify expected counts (18 Control, 20 OA per Yin 2023)\n",
    "    expected = {'Control': 18, 'OA': 20}\n",
    "    actual = condition_counts.to_dict()\n",
    "    \n",
    "    if actual.get('Control', 0) == 18 and actual.get('OA', 0) == 20:\n",
    "        print(\"\\n‚úÖ Sample counts match expected (18 Control, 20 OA)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Sample counts differ from expected (18 Control, 20 OA)\")\n",
    "        print(f\"   This is OK - we'll work with what we have.\")\n",
    "else:\n",
    "    print(\"‚ùå Could not automatically identify disease column.\")\n",
    "    print(\"   Please examine metadata_df.columns and update manually.\")\n",
    "    print(f\"\\n   Available columns: {list(metadata_df.columns)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 4 complete. Ready for Cell 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Enumerate Supplementary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Supplementary Files Available:\n",
      "============================================================\n",
      "\n",
      "üì¶ Series-level supplementary files (3):\n",
      "   1. GSE114007_OA_normalized.counts.txt.gz\n",
      "      URL: ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE114nnn/GSE114007/suppl/GSE114007_OA_normalized.counts.txt.gz\n",
      "   2. GSE114007_normal_normalized.counts.txt.gz\n",
      "      URL: ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE114nnn/GSE114007/suppl/GSE114007_normal_normalized.counts.txt.gz\n",
      "   3. GSE114007_raw_counts.xlsx\n",
      "      URL: ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE114nnn/GSE114007/suppl/GSE114007_raw_counts.xlsx\n",
      "\n",
      "üì¶ Sample-level supplementary files (checking first 3 samples):\n",
      "\n",
      "   GSM3130531:\n",
      "      (none)\n",
      "\n",
      "   GSM3130532:\n",
      "      (none)\n",
      "\n",
      "   GSM3130533:\n",
      "      (none)\n",
      "\n",
      "‚úÖ Cell 5 complete. Ready for Cell 6.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 5: ENUMERATE SUPPLEMENTARY FILES\n",
    "=====================================\n",
    "For RNA-seq datasets, expression data is in supplementary files,\n",
    "not in the GSM.table field used by microarrays.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìÅ Supplementary Files Available:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get supplementary files from the GSE\n",
    "supp_files = gse.metadata.get('supplementary_file', [])\n",
    "\n",
    "if supp_files:\n",
    "    print(f\"\\nüì¶ Series-level supplementary files ({len(supp_files)}):\")\n",
    "    for i, url in enumerate(supp_files, 1):\n",
    "        filename = url.split('/')[-1]\n",
    "        print(f\"   {i}. {filename}\")\n",
    "        print(f\"      URL: {url}\")\n",
    "else:\n",
    "    print(\"   No series-level supplementary files found.\")\n",
    "\n",
    "# Check GSM-level supplementary files (each sample may have its own)\n",
    "print(f\"\\nüì¶ Sample-level supplementary files (checking first 3 samples):\")\n",
    "gsm_supps = {}\n",
    "for i, (gsm_id, gsm) in enumerate(list(gse.gsms.items())[:3]):\n",
    "    gsm_files = gsm.metadata.get('supplementary_file', [])\n",
    "    gsm_supps[gsm_id] = gsm_files\n",
    "    print(f\"\\n   {gsm_id}:\")\n",
    "    if gsm_files:\n",
    "        for f in gsm_files:\n",
    "            print(f\"      - {f.split('/')[-1]}\")\n",
    "    else:\n",
    "        print(f\"      (none)\")\n",
    "\n",
    "# Store for later use\n",
    "SUPP_FILES = supp_files\n",
    "\n",
    "print(\"\\n‚úÖ Cell 5 complete. Ready for Cell 6.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Download Expression Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for expression matrix files...\n",
      "\n",
      "   ‚≠ê Candidate: GSE114007_OA_normalized.counts.txt.gz\n",
      "   ‚≠ê Candidate: GSE114007_normal_normalized.counts.txt.gz\n",
      "   ‚≠ê Candidate: GSE114007_raw_counts.xlsx\n",
      "\n",
      "üì• Downloading candidate files...\n",
      "   üì• Downloading: GSE114007_OA_normalized.counts.txt.gz\n",
      "   ‚úÖ Downloaded: 1.59 MB\n",
      "   üì• Downloading: GSE114007_normal_normalized.counts.txt.gz\n",
      "   ‚úÖ Downloaded: 1.41 MB\n",
      "   üì• Downloading: GSE114007_raw_counts.xlsx\n",
      "   ‚úÖ Downloaded: 3.86 MB\n",
      "\n",
      "üìÅ Downloaded files in data/raw/GSE114007:\n",
      "   GSE114007_family.soft.gz: 0.00 MB\n",
      "   GSE114007_normal_normalized.counts.txt.gz: 1.41 MB\n",
      "   GSE114007_OA_normalized.counts.txt.gz: 1.59 MB\n",
      "   GSE114007_raw_counts.xlsx: 3.86 MB\n",
      "\n",
      "‚úÖ Cell 6 complete. Ready for Cell 7.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 6: DOWNLOAD EXPRESSION MATRIX\n",
    "==================================\n",
    "Download the expression matrix from supplementary files.\n",
    "Look for files containing: counts, TPM, FPKM, or expression.\n",
    "\"\"\"\n",
    "\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def download_file(url, dest_path):\n",
    "    \"\"\"Download a file with progress indication.\"\"\"\n",
    "    print(f\"   üì• Downloading: {url.split('/')[-1]}\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, dest_path)\n",
    "        size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n",
    "        print(f\"   ‚úÖ Downloaded: {size_mb:.2f} MB\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def decompress_gz(gz_path, output_path):\n",
    "    \"\"\"Decompress a .gz file.\"\"\"\n",
    "    with gzip.open(gz_path, 'rb') as f_in:\n",
    "        with open(output_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    print(f\"   üì¶ Decompressed to: {output_path.name}\")\n",
    "\n",
    "# Identify likely expression matrix files\n",
    "expression_keywords = ['count', 'tpm', 'fpkm', 'rpkm', 'expression', 'matrix', 'abundance']\n",
    "candidate_files = []\n",
    "\n",
    "print(\"üîç Searching for expression matrix files...\\n\")\n",
    "\n",
    "for url in SUPP_FILES:\n",
    "    filename = url.split('/')[-1].lower()\n",
    "    if any(kw in filename for kw in expression_keywords):\n",
    "        candidate_files.append(url)\n",
    "        print(f\"   ‚≠ê Candidate: {url.split('/')[-1]}\")\n",
    "\n",
    "# If no obvious candidates, list all for manual selection\n",
    "if not candidate_files:\n",
    "    print(\"   ‚ö†Ô∏è No obvious expression files found by keyword.\")\n",
    "    print(\"   üìã All supplementary files:\")\n",
    "    for url in SUPP_FILES:\n",
    "        print(f\"      - {url.split('/')[-1]}\")\n",
    "    candidate_files = SUPP_FILES  # Try all\n",
    "\n",
    "# Download all candidate files\n",
    "downloaded_files = []\n",
    "\n",
    "print(\"\\nüì• Downloading candidate files...\")\n",
    "for url in candidate_files:\n",
    "    filename = url.split('/')[-1]\n",
    "    dest_path = DATA_RAW / filename\n",
    "    \n",
    "    if dest_path.exists():\n",
    "        print(f\"   ‚è≠Ô∏è Already exists: {filename}\")\n",
    "    else:\n",
    "        download_file(url, dest_path)\n",
    "    \n",
    "    downloaded_files.append(dest_path)\n",
    "\n",
    "# List downloaded files with sizes\n",
    "print(\"\\nüìÅ Downloaded files in data/raw/GSE114007:\")\n",
    "for f in DATA_RAW.iterdir():\n",
    "    size_mb = f.stat().st_size / (1024 * 1024)\n",
    "    print(f\"   {f.name}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 6 complete. Ready for Cell 7.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Parse Expression Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning for expression matrix files in data/raw/GSE114007/...\n",
      "\n",
      "   üìÑ Found: GSE114007_normal_normalized.counts.txt.gz\n",
      "   üìÑ Found: GSE114007_OA_normalized.counts.txt.gz\n",
      "\n",
      "‚úÖ Found 2 potential expression files.\n",
      "\n",
      "üì• Loading expression matrices...\n",
      "\n",
      "   Loading: GSE114007_normal_normalized.counts.txt.gz\n",
      "      ‚úÖ Shape: (23710, 20) (genes √ó samples)\n",
      "      Columns (first 3): ['Normal_Cart_10_8', 'Normal_Cart_2_2', 'Normal_Cart_3_3']\n",
      "      Index name: symbol\n",
      "      Type: Normal\n",
      "\n",
      "   Loading: GSE114007_OA_normalized.counts.txt.gz\n",
      "      ‚úÖ Shape: (23710, 22) (genes √ó samples)\n",
      "      Columns (first 3): ['OA_Cart_1_7', 'OA_Cart_10_9', 'OA_Cart_2_8']\n",
      "      Index name: symbol\n",
      "      Type: Normal\n",
      "\n",
      "‚úÖ Successfully loaded 2 expression matrices.\n",
      "\n",
      "üîó Merging expression matrices...\n",
      "\n",
      "   Found 2 matrices to merge:\n",
      "      - GSE114007_normal_normalized.counts.txt.gz: (23710, 20) (Normal)\n",
      "      - GSE114007_OA_normalized.counts.txt.gz: (23710, 22) (Normal)\n",
      "\n",
      "   Checking gene index alignment...\n",
      "      Matrix 1 vs 2: 23710 genes in common\n",
      "\n",
      "   Merging matrices (inner join on gene index)...\n",
      "   ‚ö†Ô∏è Warning: Duplicate column names detected. Keeping first occurrence.\n",
      "\n",
      "   ‚úÖ Merged matrix shape: (23710, 41)\n",
      "      Genes: 23710\n",
      "      Samples: 41\n",
      "\n",
      "============================================================\n",
      "üìä MERGED EXPRESSION MATRIX SUMMARY\n",
      "============================================================\n",
      "\n",
      "   Shape: 23710 genes √ó 41 samples\n",
      "\n",
      "   Sample columns (all 41):\n",
      "      1. Normal_Cart_10_8\n",
      "      2. Normal_Cart_2_2\n",
      "      3. Normal_Cart_3_3\n",
      "      4. Normal_Cart_4_4\n",
      "      5. Normal_Cart_5_5\n",
      "      6. Normal_Cart_6_6\n",
      "      7. Normal_Cart_7_3\n",
      "      8. Normal_Cart_9_7\n",
      "      9. normal_01\n",
      "      10. normal_02\n",
      "      11. normal_03\n",
      "      12. normal_04\n",
      "      13. normal_05\n",
      "      14. normal_06\n",
      "      15. normal_07\n",
      "      16. normal_08\n",
      "      17. normal_09\n",
      "      18. normal_10\n",
      "      19. Average Normal\n",
      "      20. Max\n",
      "      21. OA_Cart_1_7\n",
      "      22. OA_Cart_10_9\n",
      "      23. OA_Cart_2_8\n",
      "      24. OA_Cart_3_9\n",
      "      25. OA_Cart_4_10\n",
      "      26. OA_Cart_5_5\n",
      "      27. OA_Cart_6_1\n",
      "      28. OA_Cart_7_2\n",
      "      29. OA_Cart_8_5\n",
      "      30. OA_Cart_9_6\n",
      "      31. OA_01\n",
      "      32. OA_02\n",
      "      33. OA_03\n",
      "      34. OA_04\n",
      "      35. OA_05\n",
      "      36. OA_06\n",
      "      37. OA_07\n",
      "      38. OA_08\n",
      "      39. OA_09\n",
      "      40. OA_10\n",
      "      41. Average OA\n",
      "\n",
      "   Gene index (first 5): ['FN1', 'COMP', 'MALAT1', 'CHI3L2', 'CLU']\n",
      "\n",
      "   üìã Preview (5√ó5):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal_Cart_10_8</th>\n",
       "      <th>Normal_Cart_2_2</th>\n",
       "      <th>Normal_Cart_3_3</th>\n",
       "      <th>Normal_Cart_4_4</th>\n",
       "      <th>Normal_Cart_5_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN1</th>\n",
       "      <td>16.277134</td>\n",
       "      <td>15.429753</td>\n",
       "      <td>15.428266</td>\n",
       "      <td>16.305868</td>\n",
       "      <td>14.635041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMP</th>\n",
       "      <td>15.371944</td>\n",
       "      <td>14.515260</td>\n",
       "      <td>14.813281</td>\n",
       "      <td>14.776144</td>\n",
       "      <td>14.048698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MALAT1</th>\n",
       "      <td>15.441039</td>\n",
       "      <td>14.574888</td>\n",
       "      <td>15.053004</td>\n",
       "      <td>14.793931</td>\n",
       "      <td>14.773987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHI3L2</th>\n",
       "      <td>7.645584</td>\n",
       "      <td>5.860772</td>\n",
       "      <td>6.055734</td>\n",
       "      <td>8.496841</td>\n",
       "      <td>6.743966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLU</th>\n",
       "      <td>15.105566</td>\n",
       "      <td>14.493329</td>\n",
       "      <td>14.849689</td>\n",
       "      <td>14.704724</td>\n",
       "      <td>15.092099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Normal_Cart_10_8  Normal_Cart_2_2  Normal_Cart_3_3  Normal_Cart_4_4  \\\n",
       "symbol                                                                        \n",
       "FN1            16.277134        15.429753        15.428266        16.305868   \n",
       "COMP           15.371944        14.515260        14.813281        14.776144   \n",
       "MALAT1         15.441039        14.574888        15.053004        14.793931   \n",
       "CHI3L2          7.645584         5.860772         6.055734         8.496841   \n",
       "CLU            15.105566        14.493329        14.849689        14.704724   \n",
       "\n",
       "        Normal_Cart_5_5  \n",
       "symbol                   \n",
       "FN1           14.635041  \n",
       "COMP          14.048698  \n",
       "MALAT1        14.773987  \n",
       "CHI3L2         6.743966  \n",
       "CLU           15.092099  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Column breakdown:\n",
      "      Normal/Control samples: 19\n",
      "      OA samples: 21\n",
      "      Other/Unclassified: 1\n",
      "\n",
      "‚úÖ Cell 7 complete. Ready for Cell 8.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 7 (CORRECTED): PARSE AND MERGE EXPRESSION MATRICES\n",
    "========================================================\n",
    "GSE114007 stores Normal and OA samples in SEPARATE files.\n",
    "This cell loads BOTH and merges them into a single matrix.\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_expression_file(filepath):\n",
    "    \"\"\"\n",
    "    Load a single expression file, handling .gz compression.\n",
    "    Returns DataFrame with genes as index, samples as columns.\n",
    "    \"\"\"\n",
    "    filename = filepath.name\n",
    "    print(f\"   Loading: {filename}\")\n",
    "    \n",
    "    # Determine if gzipped\n",
    "    is_gzipped = filename.endswith('.gz')\n",
    "    \n",
    "    # Try different separators\n",
    "    separators = ['\\t', ',', ' ']\n",
    "    \n",
    "    for sep in separators:\n",
    "        try:\n",
    "            if is_gzipped:\n",
    "                df = pd.read_csv(filepath, compression='gzip', sep=sep, index_col=0)\n",
    "            else:\n",
    "                df = pd.read_csv(filepath, sep=sep, index_col=0)\n",
    "            \n",
    "            # Check if it looks like expression data (at least 10 columns)\n",
    "            if df.shape[1] >= 10:\n",
    "                print(f\"      ‚úÖ Shape: {df.shape} (genes √ó samples)\")\n",
    "                print(f\"      Columns (first 3): {list(df.columns[:3])}\")\n",
    "                print(f\"      Index name: {df.index.name}\")\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"      ‚ùå Could not parse {filename}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# --- STEP 1: Find all expression matrix files ---\n",
    "print(\"üîç Scanning for expression matrix files in data/raw/GSE114007/...\\n\")\n",
    "\n",
    "expression_files = []\n",
    "for f in sorted(DATA_RAW.iterdir()):\n",
    "    fname_lower = f.name.lower()\n",
    "    # Look for normalized count files (typical GEO naming)\n",
    "    if any(kw in fname_lower for kw in ['normalized', 'counts', 'expression', 'fpkm', 'tpm']):\n",
    "        if fname_lower.endswith(('.txt.gz', '.csv.gz', '.tsv.gz', '.txt', '.csv', '.tsv')):\n",
    "            expression_files.append(f)\n",
    "            print(f\"   üìÑ Found: {f.name}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(expression_files)} potential expression files.\\n\")\n",
    "\n",
    "\n",
    "# --- STEP 2: Load each expression file ---\n",
    "print(\"üì• Loading expression matrices...\\n\")\n",
    "\n",
    "loaded_matrices = {}\n",
    "for filepath in expression_files:\n",
    "    df = load_expression_file(filepath)\n",
    "    if df is not None and df.shape[1] >= 5:  # At least 5 samples\n",
    "        # Identify if this is Normal or OA based on filename or column names\n",
    "        fname_lower = filepath.name.lower()\n",
    "        if 'normal' in fname_lower or 'control' in fname_lower:\n",
    "            matrix_type = 'Normal'\n",
    "        elif 'oa' in fname_lower or 'osteoarthritis' in fname_lower:\n",
    "            matrix_type = 'OA'\n",
    "        else:\n",
    "            # Try to infer from column names\n",
    "            cols_str = ' '.join(df.columns[:5]).lower()\n",
    "            if 'normal' in cols_str or 'control' in cols_str:\n",
    "                matrix_type = 'Normal'\n",
    "            elif 'oa' in cols_str:\n",
    "                matrix_type = 'OA'\n",
    "            else:\n",
    "                matrix_type = 'Unknown'\n",
    "        \n",
    "        loaded_matrices[filepath.name] = {\n",
    "            'df': df,\n",
    "            'type': matrix_type,\n",
    "            'shape': df.shape\n",
    "        }\n",
    "        print(f\"      Type: {matrix_type}\\n\")\n",
    "\n",
    "print(f\"‚úÖ Successfully loaded {len(loaded_matrices)} expression matrices.\\n\")\n",
    "\n",
    "\n",
    "# --- STEP 3: Merge matrices if multiple exist ---\n",
    "print(\"üîó Merging expression matrices...\\n\")\n",
    "\n",
    "if len(loaded_matrices) == 0:\n",
    "    print(\"‚ùå No expression matrices loaded. Check file formats.\")\n",
    "    expression_df = None\n",
    "\n",
    "elif len(loaded_matrices) == 1:\n",
    "    # Single file - use as-is\n",
    "    key = list(loaded_matrices.keys())[0]\n",
    "    expression_df = loaded_matrices[key]['df']\n",
    "    print(f\"   Single matrix found: {key}\")\n",
    "    print(f\"   Shape: {expression_df.shape}\")\n",
    "\n",
    "else:\n",
    "    # Multiple files - need to merge\n",
    "    print(f\"   Found {len(loaded_matrices)} matrices to merge:\")\n",
    "    for fname, info in loaded_matrices.items():\n",
    "        print(f\"      - {fname}: {info['shape']} ({info['type']})\")\n",
    "    \n",
    "    # Get list of DataFrames\n",
    "    dfs_to_merge = [info['df'] for info in loaded_matrices.values()]\n",
    "    \n",
    "    # Check if gene indices match\n",
    "    print(\"\\n   Checking gene index alignment...\")\n",
    "    first_index = set(dfs_to_merge[0].index)\n",
    "    all_match = True\n",
    "    for i, df in enumerate(dfs_to_merge[1:], 2):\n",
    "        other_index = set(df.index)\n",
    "        overlap = len(first_index & other_index)\n",
    "        print(f\"      Matrix 1 vs {i}: {overlap} genes in common\")\n",
    "        if overlap < len(first_index) * 0.9:  # Less than 90% overlap\n",
    "            all_match = False\n",
    "    \n",
    "    if all_match or True:  # Proceed anyway with inner join\n",
    "        # Merge on common genes (inner join on index)\n",
    "        print(\"\\n   Merging matrices (inner join on gene index)...\")\n",
    "        \n",
    "        # Use concat with inner join on index\n",
    "        expression_df = pd.concat(dfs_to_merge, axis=1, join='inner')\n",
    "        \n",
    "        # Check for duplicate column names\n",
    "        if expression_df.columns.duplicated().any():\n",
    "            print(\"   ‚ö†Ô∏è Warning: Duplicate column names detected. Keeping first occurrence.\")\n",
    "            expression_df = expression_df.loc[:, ~expression_df.columns.duplicated()]\n",
    "        \n",
    "        print(f\"\\n   ‚úÖ Merged matrix shape: {expression_df.shape}\")\n",
    "        print(f\"      Genes: {expression_df.shape[0]}\")\n",
    "        print(f\"      Samples: {expression_df.shape[1]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# --- STEP 4: Display merged matrix info ---\n",
    "if expression_df is not None:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä MERGED EXPRESSION MATRIX SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\n   Shape: {expression_df.shape[0]} genes √ó {expression_df.shape[1]} samples\")\n",
    "    print(f\"\\n   Sample columns (all {expression_df.shape[1]}):\")\n",
    "    for i, col in enumerate(expression_df.columns):\n",
    "        print(f\"      {i+1}. {col}\")\n",
    "    \n",
    "    print(f\"\\n   Gene index (first 5): {list(expression_df.index[:5])}\")\n",
    "    print(f\"\\n   üìã Preview (5√ó5):\")\n",
    "    display(expression_df.iloc[:5, :5])\n",
    "    \n",
    "    # Check for Normal vs OA in column names\n",
    "    normal_cols = [c for c in expression_df.columns if 'normal' in c.lower()]\n",
    "    oa_cols = [c for c in expression_df.columns if 'oa' in c.lower()]\n",
    "    print(f\"\\n   Column breakdown:\")\n",
    "    print(f\"      Normal/Control samples: {len(normal_cols)}\")\n",
    "    print(f\"      OA samples: {len(oa_cols)}\")\n",
    "    print(f\"      Other/Unclassified: {expression_df.shape[1] - len(normal_cols) - len(oa_cols)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 7 complete. Ready for Cell 8.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Alternative - Try Series Matrix File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Expression matrix already loaded from supplementary files.\n",
      "   Shape: (23710, 41)\n",
      "   Skipping series matrix attempt.\n",
      "\n",
      "‚úÖ Cell 8 complete. Ready for Cell 9.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 8: ALTERNATIVE - TRY SERIES MATRIX FILE\n",
    "============================================\n",
    "If supplementary files didn't work, try the series matrix file.\n",
    "This is more common for microarray but sometimes works for RNA-seq.\n",
    "\"\"\"\n",
    "\n",
    "# Check if we already have expression data\n",
    "if expression_df is not None and expression_df.shape[1] >= 30:\n",
    "    print(\"‚úÖ Expression matrix already loaded from supplementary files.\")\n",
    "    print(f\"   Shape: {expression_df.shape}\")\n",
    "    print(\"   Skipping series matrix attempt.\")\n",
    "else:\n",
    "    print(\"üîç Attempting to extract expression from GEOparse pivot...\")\n",
    "    \n",
    "    try:\n",
    "        # Try GEOparse's built-in pivot method\n",
    "        pivoted = gse.pivot_samples('VALUE')\n",
    "        \n",
    "        if pivoted is not None and not pivoted.empty:\n",
    "            print(f\"   ‚úÖ Pivot successful! Shape: {pivoted.shape}\")\n",
    "            expression_df = pivoted\n",
    "            parsed_file = \"GEOparse pivot\"\n",
    "            display(expression_df.iloc[:5, :5])\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è Pivot returned empty (typical for RNA-seq).\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Pivot failed: {e}\")\n",
    "    \n",
    "    # Try GSM tables directly\n",
    "    print(\"\\nüîç Checking individual GSM tables...\")\n",
    "    sample_gsm = list(gse.gsms.values())[0]\n",
    "    \n",
    "    if hasattr(sample_gsm, 'table') and sample_gsm.table is not None and not sample_gsm.table.empty:\n",
    "        print(f\"   ‚úÖ GSM tables available. Columns: {list(sample_gsm.table.columns)}\")\n",
    "        print(f\"   Shape: {sample_gsm.table.shape}\")\n",
    "        \n",
    "        # Build expression matrix from GSM tables\n",
    "        all_tables = {}\n",
    "        for gsm_id, gsm in gse.gsms.items():\n",
    "            if hasattr(gsm, 'table') and gsm.table is not None and not gsm.table.empty:\n",
    "                # Assume first column is gene ID, second is expression value\n",
    "                if len(gsm.table.columns) >= 2:\n",
    "                    gene_col = gsm.table.columns[0]\n",
    "                    val_col = gsm.table.columns[1]\n",
    "                    all_tables[gsm_id] = gsm.table.set_index(gene_col)[val_col]\n",
    "        \n",
    "        if all_tables:\n",
    "            expression_df = pd.DataFrame(all_tables)\n",
    "            parsed_file = \"GSM tables\"\n",
    "            print(f\"   ‚úÖ Built matrix from GSM tables: {expression_df.shape}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è GSM tables are empty (typical for RNA-seq deposited without processed data).\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 8 complete. Ready for Cell 9.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Validate and Align Expression with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Aligning expression columns with metadata...\n",
      "\n",
      "   Expression matrix shape: (23710, 41)\n",
      "   Metadata shape: (38, 9)\n",
      "\n",
      "   Expression columns (first 5): ['Normal_Cart_10_8', 'Normal_Cart_2_2', 'Normal_Cart_3_3', 'Normal_Cart_4_4', 'Normal_Cart_5_5']\n",
      "   Metadata sample_id (first 5): ['GSM3130531', 'GSM3130532', 'GSM3130533', 'GSM3130534', 'GSM3130535']\n",
      "   Metadata titles (first 5): ['Normal_Cart_2_2', 'Normal_Cart_3_3', 'Normal_Cart_4_4', 'Normal_Cart_5_5', 'Normal_Cart_6_6']\n",
      "\n",
      "   Strategy A - Direct GSM match: 0 matches\n",
      "   Strategy B - Title matching: 38 matches\n",
      "   Strategy C - Pattern matching: 0 matches\n",
      "\n",
      "   ‚úÖ Using Strategy B (title matching)\n",
      "\n",
      "   Total matched: 38 / 41 expression columns\n",
      "\n",
      "   ‚úÖ Aligned expression shape: (23710, 38)\n",
      "   ‚úÖ Aligned metadata shape: (38, 9)\n",
      "\n",
      "   üìã Sample mapping (first 10):\n",
      "      Normal_Cart_10_8 ‚Üí GSM3130538 (Control)\n",
      "      Normal_Cart_2_2 ‚Üí GSM3130531 (Control)\n",
      "      Normal_Cart_3_3 ‚Üí GSM3130532 (Control)\n",
      "      Normal_Cart_4_4 ‚Üí GSM3130533 (Control)\n",
      "      Normal_Cart_5_5 ‚Üí GSM3130534 (Control)\n",
      "      Normal_Cart_6_6 ‚Üí GSM3130535 (Control)\n",
      "      Normal_Cart_7_3 ‚Üí GSM3130536 (Control)\n",
      "      Normal_Cart_9_7 ‚Üí GSM3130537 (Control)\n",
      "      normal_01 ‚Üí GSM3130549 (Control)\n",
      "      normal_02 ‚Üí GSM3130550 (Control)\n",
      "\n",
      "   üìä Condition distribution after alignment:\n",
      "      OA: 20\n",
      "      Control: 18\n",
      "\n",
      "‚úÖ Cell 9 complete. Ready for Cell 10.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 9 (CORRECTED): ALIGN EXPRESSION COLUMNS WITH METADATA\n",
    "===========================================================\n",
    "The expression columns use names like 'Normal_Cart_10_8', 'OA_Cart_1_7'\n",
    "The metadata uses GSM IDs like 'GSM3130531'.\n",
    "\n",
    "We need to match via the metadata 'title' column or other characteristics.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "if expression_df is None or expression_df.empty:\n",
    "    print(\"‚ùå STOP: No expression matrix available.\")\n",
    "    print(\"   Run Cell 7 first to load and merge expression data.\")\n",
    "else:\n",
    "    print(\"üîó Aligning expression columns with metadata...\\n\")\n",
    "    \n",
    "    print(f\"   Expression matrix shape: {expression_df.shape}\")\n",
    "    print(f\"   Metadata shape: {metadata_df.shape}\")\n",
    "    print()\n",
    "    \n",
    "    # --- STEP 1: Get sample IDs from both sources ---\n",
    "    expr_columns = list(expression_df.columns)\n",
    "    meta_sample_ids = list(metadata_df['sample_id'])\n",
    "    \n",
    "    print(f\"   Expression columns (first 5): {expr_columns[:5]}\")\n",
    "    print(f\"   Metadata sample_id (first 5): {meta_sample_ids[:5]}\")\n",
    "    \n",
    "    # Check if metadata has a 'title' column we can match\n",
    "    if 'title' in metadata_df.columns:\n",
    "        meta_titles = list(metadata_df['title'])\n",
    "        print(f\"   Metadata titles (first 5): {meta_titles[:5]}\")\n",
    "    print()\n",
    "    \n",
    "    # --- STEP 2: Try different matching strategies ---\n",
    "    \n",
    "    # Strategy A: Direct match (expression columns ARE GSM IDs)\n",
    "    direct_overlap = set(expr_columns) & set(meta_sample_ids)\n",
    "    print(f\"   Strategy A - Direct GSM match: {len(direct_overlap)} matches\")\n",
    "    \n",
    "    # Strategy B: Match expression column to metadata title\n",
    "    title_matches = {}\n",
    "    if 'title' in metadata_df.columns:\n",
    "        for expr_col in expr_columns:\n",
    "            # Clean the expression column name for matching\n",
    "            expr_clean = expr_col.strip()\n",
    "            \n",
    "            for idx, row in metadata_df.iterrows():\n",
    "                title = str(row['title']).strip()\n",
    "                gsm_id = row['sample_id']\n",
    "                \n",
    "                # Try exact match\n",
    "                if expr_clean == title:\n",
    "                    title_matches[expr_col] = gsm_id\n",
    "                    break\n",
    "                \n",
    "                # Try partial match (expression name contained in title or vice versa)\n",
    "                if expr_clean in title or title in expr_clean:\n",
    "                    title_matches[expr_col] = gsm_id\n",
    "                    break\n",
    "                \n",
    "                # Try matching without underscores/spaces\n",
    "                expr_normalized = expr_clean.lower().replace('_', '').replace(' ', '').replace('-', '')\n",
    "                title_normalized = title.lower().replace('_', '').replace(' ', '').replace('-', '')\n",
    "                if expr_normalized == title_normalized:\n",
    "                    title_matches[expr_col] = gsm_id\n",
    "                    break\n",
    "    \n",
    "    print(f\"   Strategy B - Title matching: {len(title_matches)} matches\")\n",
    "    \n",
    "    # Strategy C: Pattern-based matching for 'Normal_Cart_X_Y' / 'OA_Cart_X_Y' format\n",
    "    pattern_matches = {}\n",
    "    if len(title_matches) < len(expr_columns) * 0.5:\n",
    "        print(\"\\n   Trying Strategy C - Pattern-based matching...\")\n",
    "        \n",
    "        # Build lookup from metadata titles\n",
    "        title_to_gsm = {}\n",
    "        if 'title' in metadata_df.columns:\n",
    "            for idx, row in metadata_df.iterrows():\n",
    "                title = str(row['title'])\n",
    "                gsm_id = row['sample_id']\n",
    "                # Store multiple normalized versions\n",
    "                title_to_gsm[title] = gsm_id\n",
    "                title_to_gsm[title.lower()] = gsm_id\n",
    "                title_to_gsm[title.replace(' ', '_')] = gsm_id\n",
    "                title_to_gsm[title.replace('_', ' ')] = gsm_id\n",
    "        \n",
    "        for expr_col in expr_columns:\n",
    "            if expr_col in pattern_matches:\n",
    "                continue\n",
    "            \n",
    "            # Try various transformations\n",
    "            variants = [\n",
    "                expr_col,\n",
    "                expr_col.replace('_', ' '),\n",
    "                expr_col.lower(),\n",
    "                expr_col.lower().replace('_', ' '),\n",
    "            ]\n",
    "            \n",
    "            for variant in variants:\n",
    "                if variant in title_to_gsm:\n",
    "                    pattern_matches[expr_col] = title_to_gsm[variant]\n",
    "                    break\n",
    "    \n",
    "    print(f\"   Strategy C - Pattern matching: {len(pattern_matches)} matches\")\n",
    "    \n",
    "    # --- STEP 3: Use best matching strategy ---\n",
    "    if len(direct_overlap) >= len(expr_columns) * 0.9:\n",
    "        print(\"\\n   ‚úÖ Using Strategy A (direct GSM match)\")\n",
    "        col_to_gsm = {col: col for col in expr_columns if col in meta_sample_ids}\n",
    "    elif len(title_matches) >= len(expr_columns) * 0.5:\n",
    "        print(\"\\n   ‚úÖ Using Strategy B (title matching)\")\n",
    "        col_to_gsm = title_matches\n",
    "    elif len(pattern_matches) >= len(expr_columns) * 0.5:\n",
    "        print(\"\\n   ‚úÖ Using Strategy C (pattern matching)\")\n",
    "        col_to_gsm = pattern_matches\n",
    "    else:\n",
    "        # Strategy D: Positional matching as last resort\n",
    "        # Match by condition (Normal vs OA) and position\n",
    "        print(\"\\n   ‚ö†Ô∏è No good ID match found. Attempting positional matching by condition...\")\n",
    "        \n",
    "        col_to_gsm = {}\n",
    "        \n",
    "        # Separate expression columns by type\n",
    "        normal_expr_cols = sorted([c for c in expr_columns if 'normal' in c.lower()])\n",
    "        oa_expr_cols = sorted([c for c in expr_columns if 'oa' in c.lower()])\n",
    "        \n",
    "        # Separate metadata by condition\n",
    "        if 'condition' in metadata_df.columns:\n",
    "            normal_meta = metadata_df[metadata_df['condition'] == 'Control'].sort_values('sample_id')\n",
    "            oa_meta = metadata_df[metadata_df['condition'] == 'OA'].sort_values('sample_id')\n",
    "        else:\n",
    "            # Try to infer from title\n",
    "            normal_meta = metadata_df[metadata_df['title'].str.lower().str.contains('normal|control', na=False)].sort_values('sample_id')\n",
    "            oa_meta = metadata_df[~metadata_df['title'].str.lower().str.contains('normal|control', na=False)].sort_values('sample_id')\n",
    "        \n",
    "        print(f\"\\n   Normal: {len(normal_expr_cols)} expr cols, {len(normal_meta)} metadata rows\")\n",
    "        print(f\"   OA: {len(oa_expr_cols)} expr cols, {len(oa_meta)} metadata rows\")\n",
    "        \n",
    "        # Match by position within each group\n",
    "        for i, expr_col in enumerate(normal_expr_cols):\n",
    "            if i < len(normal_meta):\n",
    "                col_to_gsm[expr_col] = normal_meta.iloc[i]['sample_id']\n",
    "        \n",
    "        for i, expr_col in enumerate(oa_expr_cols):\n",
    "            if i < len(oa_meta):\n",
    "                col_to_gsm[expr_col] = oa_meta.iloc[i]['sample_id']\n",
    "        \n",
    "        print(f\"\\n   Strategy D - Positional matching: {len(col_to_gsm)} matches\")\n",
    "    \n",
    "    # --- STEP 4: Apply mapping and filter ---\n",
    "    print(f\"\\n   Total matched: {len(col_to_gsm)} / {len(expr_columns)} expression columns\")\n",
    "    \n",
    "    if len(col_to_gsm) > 0:\n",
    "        # Rename columns to GSM IDs\n",
    "        expression_df_aligned = expression_df.rename(columns=col_to_gsm)\n",
    "        \n",
    "        # Keep only columns that were mapped\n",
    "        mapped_gsm_ids = list(col_to_gsm.values())\n",
    "        expression_df_aligned = expression_df_aligned[mapped_gsm_ids]\n",
    "        \n",
    "        # Filter metadata to matched samples\n",
    "        metadata_df_aligned = metadata_df[metadata_df['sample_id'].isin(mapped_gsm_ids)].copy()\n",
    "        metadata_df_aligned = metadata_df_aligned.set_index('sample_id').loc[mapped_gsm_ids].reset_index()\n",
    "        \n",
    "        # Update the main dataframes\n",
    "        expression_df = expression_df_aligned\n",
    "        metadata_df = metadata_df_aligned\n",
    "        \n",
    "        print(f\"\\n   ‚úÖ Aligned expression shape: {expression_df.shape}\")\n",
    "        print(f\"   ‚úÖ Aligned metadata shape: {metadata_df.shape}\")\n",
    "        \n",
    "        # Show mapping table\n",
    "        print(f\"\\n   üìã Sample mapping (first 10):\")\n",
    "        mapping_preview = [(orig, gsm) for orig, gsm in list(col_to_gsm.items())[:10]]\n",
    "        for orig, gsm in mapping_preview:\n",
    "            # Get condition for this sample\n",
    "            cond = metadata_df[metadata_df['sample_id'] == gsm]['condition'].values\n",
    "            cond_str = cond[0] if len(cond) > 0 else 'Unknown'\n",
    "            print(f\"      {orig} ‚Üí {gsm} ({cond_str})\")\n",
    "        \n",
    "        # Verify condition distribution\n",
    "        if 'condition' in metadata_df.columns:\n",
    "            print(f\"\\n   üìä Condition distribution after alignment:\")\n",
    "            for cond, count in metadata_df['condition'].value_counts().items():\n",
    "                print(f\"      {cond}: {count}\")\n",
    "    else:\n",
    "        print(\"\\n   ‚ùå ERROR: Could not match expression columns to metadata.\")\n",
    "        print(\"   Manual inspection required. See mapping preview above.\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 9 complete. Ready for Cell 10.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Create ML-Ready Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating ML-ready matrix...\n",
      "\n",
      "   Step 1: Converting to numeric...\n",
      "   Step 2: Filtering genes...\n",
      "      Removed 0 empty/zero genes. Remaining: 23710\n",
      "   Step 3: Log2(x + 1) transformation...\n",
      "   Step 4: Per-gene z-score standardization...\n",
      "\n",
      "‚úÖ ML matrix created:\n",
      "   Shape: 23710 genes √ó 38 samples\n",
      "   Value range: [-5.67, 6.00]\n",
      "   Mean (should be ~0): 0.0000\n",
      "   Std (should be ~1): 0.9273\n",
      "\n",
      "üìä ML Matrix Preview (5√ó5):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM3130538</th>\n",
       "      <th>GSM3130531</th>\n",
       "      <th>GSM3130532</th>\n",
       "      <th>GSM3130533</th>\n",
       "      <th>GSM3130534</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN1</th>\n",
       "      <td>0.327683</td>\n",
       "      <td>-0.501095</td>\n",
       "      <td>-0.502587</td>\n",
       "      <td>0.355068</td>\n",
       "      <td>-1.318160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMP</th>\n",
       "      <td>1.375804</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>1.013753</td>\n",
       "      <td>0.989234</td>\n",
       "      <td>0.496953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MALAT1</th>\n",
       "      <td>0.830341</td>\n",
       "      <td>-0.070694</td>\n",
       "      <td>0.432696</td>\n",
       "      <td>0.161819</td>\n",
       "      <td>0.140782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHI3L2</th>\n",
       "      <td>-0.730324</td>\n",
       "      <td>-1.603103</td>\n",
       "      <td>-1.497339</td>\n",
       "      <td>-0.375856</td>\n",
       "      <td>-1.146031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLU</th>\n",
       "      <td>0.970641</td>\n",
       "      <td>0.324612</td>\n",
       "      <td>0.703679</td>\n",
       "      <td>0.550515</td>\n",
       "      <td>0.956697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GSM3130538  GSM3130531  GSM3130532  GSM3130533  GSM3130534\n",
       "symbol                                                            \n",
       "FN1       0.327683   -0.501095   -0.502587    0.355068   -1.318160\n",
       "COMP      1.375804    0.815348    1.013753    0.989234    0.496953\n",
       "MALAT1    0.830341   -0.070694    0.432696    0.161819    0.140782\n",
       "CHI3L2   -0.730324   -1.603103   -1.497339   -0.375856   -1.146031\n",
       "CLU       0.970641    0.324612    0.703679    0.550515    0.956697"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Cell 10 complete. Ready for Cell 11.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 10: CREATE ML-READY MATRIX\n",
    "===============================\n",
    "Transform raw expression into ML-ready format:\n",
    "1. log2(x + 1) transformation\n",
    "2. Per-gene z-score standardization\n",
    "\"\"\"\n",
    "\n",
    "if expression_df is None or expression_df.empty:\n",
    "    print(\"‚ùå Cannot create ML matrix - no expression data loaded.\")\n",
    "else:\n",
    "    print(\"üîß Creating ML-ready matrix...\\n\")\n",
    "    \n",
    "    # Store raw source matrix\n",
    "    raw_source_matrix = expression_df.copy()\n",
    "    \n",
    "    # Step 1: Ensure numeric\n",
    "    print(\"   Step 1: Converting to numeric...\")\n",
    "    raw_source_matrix = raw_source_matrix.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Step 2: Remove genes with all NaN or all zero\n",
    "    print(\"   Step 2: Filtering genes...\")\n",
    "    n_before = raw_source_matrix.shape[0]\n",
    "    raw_source_matrix = raw_source_matrix.dropna(how='all')\n",
    "    raw_source_matrix = raw_source_matrix[(raw_source_matrix != 0).any(axis=1)]\n",
    "    n_after = raw_source_matrix.shape[0]\n",
    "    print(f\"      Removed {n_before - n_after} empty/zero genes. Remaining: {n_after}\")\n",
    "    \n",
    "    # Step 3: Log2(x + 1) transformation\n",
    "    print(\"   Step 3: Log2(x + 1) transformation...\")\n",
    "    # Handle negative values (shouldn't exist, but just in case)\n",
    "    raw_source_matrix = raw_source_matrix.clip(lower=0)\n",
    "    ml_matrix = np.log2(raw_source_matrix + 1)\n",
    "    \n",
    "    # Step 4: Per-gene z-score (across samples)\n",
    "    print(\"   Step 4: Per-gene z-score standardization...\")\n",
    "    gene_means = ml_matrix.mean(axis=1)\n",
    "    gene_stds = ml_matrix.std(axis=1)\n",
    "    # Avoid division by zero\n",
    "    gene_stds = gene_stds.replace(0, 1)\n",
    "    ml_matrix = ml_matrix.sub(gene_means, axis=0).div(gene_stds, axis=0)\n",
    "    \n",
    "    print(f\"\\n‚úÖ ML matrix created:\")\n",
    "    print(f\"   Shape: {ml_matrix.shape[0]} genes √ó {ml_matrix.shape[1]} samples\")\n",
    "    print(f\"   Value range: [{ml_matrix.min().min():.2f}, {ml_matrix.max().max():.2f}]\")\n",
    "    print(f\"   Mean (should be ~0): {ml_matrix.values.mean():.4f}\")\n",
    "    print(f\"   Std (should be ~1): {ml_matrix.values.std():.4f}\")\n",
    "    \n",
    "    print(\"\\nüìä ML Matrix Preview (5√ó5):\")\n",
    "    display(ml_matrix.iloc[:5, :5])\n",
    "\n",
    "print(\"\\n‚úÖ Cell 10 complete. Ready for Cell 11.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Check for Key Genes (PF4, RNMT, RBM24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking for key genes...\n",
      "\n",
      "   ‚úÖ PF4: Found (mean raw expression: 0.03)\n",
      "   ‚ùå CXCL4: Not found\n",
      "   ‚úÖ RNMT: Found (mean raw expression: 6.42)\n",
      "   ‚úÖ RBM24: Found (mean raw expression: 0.62)\n",
      "   ‚úÖ IL1B: Found (mean raw expression: 0.06)\n",
      "   ‚úÖ TNF: Found (mean raw expression: 0.12)\n",
      "   ‚úÖ MMP13: Found (mean raw expression: 2.80)\n",
      "   ‚úÖ COL2A1: Found (mean raw expression: 12.86)\n",
      "\n",
      "üìä Summary:\n",
      "   Found: 7/8\n",
      "   Missing: ['CXCL4']\n",
      "\n",
      "üìã Sample gene names in index (first 20):\n",
      "   ['FN1', 'COMP', 'MALAT1', 'CHI3L2', 'CLU', 'DCN', 'PRELP', 'CILP', 'CHI3L1', 'GPX3', 'COL2A1', 'VIM', 'MMP3', 'MT2A', 'ACAN', 'SOD2', 'FMOD', 'SERPINA1', 'LUM', 'COL3A1']\n",
      "\n",
      "‚úÖ Cell 11 complete. Ready for Cell 12.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 11: CHECK FOR KEY GENES\n",
    "============================\n",
    "Verify presence of genes we'll track:\n",
    "- PF4/CXCL4: Anti-aging factor from Pinho lab\n",
    "- RNMT, RBM24: Validated OA markers from Yin 2023\n",
    "\"\"\"\n",
    "\n",
    "if expression_df is None or expression_df.empty:\n",
    "    print(\"‚ùå Cannot check genes - no expression data loaded.\")\n",
    "else:\n",
    "    key_genes = ['PF4', 'CXCL4', 'RNMT', 'RBM24', 'IL1B', 'TNF', 'MMP13', 'COL2A1']\n",
    "    \n",
    "    print(\"üîç Checking for key genes...\\n\")\n",
    "    \n",
    "    # Get gene index as strings for searching\n",
    "    gene_index = raw_source_matrix.index.astype(str).str.upper()\n",
    "    \n",
    "    found_genes = []\n",
    "    missing_genes = []\n",
    "    \n",
    "    for gene in key_genes:\n",
    "        # Try exact match\n",
    "        if gene.upper() in gene_index.values:\n",
    "            found_genes.append(gene)\n",
    "            # Get actual index name\n",
    "            idx = raw_source_matrix.index[gene_index == gene.upper()][0]\n",
    "            mean_expr = raw_source_matrix.loc[idx].mean()\n",
    "            print(f\"   ‚úÖ {gene}: Found (mean raw expression: {mean_expr:.2f})\")\n",
    "        else:\n",
    "            # Try partial match\n",
    "            partial_matches = gene_index[gene_index.str.contains(gene.upper())]\n",
    "            if len(partial_matches) > 0:\n",
    "                found_genes.append(gene)\n",
    "                print(f\"   ‚ö†Ô∏è {gene}: Partial match found: {partial_matches.values[:3]}\")\n",
    "            else:\n",
    "                missing_genes.append(gene)\n",
    "                print(f\"   ‚ùå {gene}: Not found\")\n",
    "    \n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    print(f\"   Found: {len(found_genes)}/{len(key_genes)}\")\n",
    "    print(f\"   Missing: {missing_genes}\")\n",
    "    \n",
    "    # Show some example gene names from the index\n",
    "    print(f\"\\nüìã Sample gene names in index (first 20):\")\n",
    "    print(f\"   {list(raw_source_matrix.index[:20])}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 11 complete. Ready for Cell 12.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: GSE114007_metadata.csv\n",
      "   Shape: (38, 9)\n",
      "\n",
      "‚úÖ Saved: GSE114007_raw_source_matrix.csv\n",
      "   Shape: (23710, 38)\n",
      "\n",
      "‚úÖ Saved: GSE114007_ml_matrix.csv\n",
      "   Shape: (23710, 38)\n",
      "\n",
      "üìÅ All files in processed/:\n",
      "   .gitkeep: 0.0 KB\n",
      "   GSE114007_metadata.csv: 3.1 KB\n",
      "   GSE114007_ml_matrix.csv: 15966.0 KB\n",
      "   GSE114007_raw_source_matrix.csv: 7932.0 KB\n",
      "\n",
      "‚úÖ Cell 12 complete. Ready for Cell 13 (Final Checkpoint).\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 12: SAVE OUTPUTS\n",
    "=====================\n",
    "Save the three required files:\n",
    "1. metadata.csv\n",
    "2. raw_source_matrix.csv\n",
    "3. ml_matrix.csv\n",
    "\"\"\"\n",
    "\n",
    "if expression_df is None or expression_df.empty:\n",
    "    print(\"‚ùå Cannot save - no expression data loaded.\")\n",
    "    print(\"\\nüìã MANUAL ACTION REQUIRED:\")\n",
    "    print(\"   See Cell 9 output for instructions.\")\n",
    "else:\n",
    "    # Save metadata\n",
    "    metadata_path = DATA_PROCESSED / \"GSE114007_metadata.csv\"\n",
    "    metadata_df.to_csv(metadata_path, index=False)\n",
    "    print(f\"‚úÖ Saved: {metadata_path.name}\")\n",
    "    print(f\"   Shape: {metadata_df.shape}\")\n",
    "    \n",
    "    # Save raw source matrix\n",
    "    raw_path = DATA_PROCESSED / \"GSE114007_raw_source_matrix.csv\"\n",
    "    raw_source_matrix.to_csv(raw_path)\n",
    "    print(f\"\\n‚úÖ Saved: {raw_path.name}\")\n",
    "    print(f\"   Shape: {raw_source_matrix.shape}\")\n",
    "    \n",
    "    # Save ML matrix\n",
    "    ml_path = DATA_PROCESSED / \"GSE114007_ml_matrix.csv\"\n",
    "    ml_matrix.to_csv(ml_path)\n",
    "    print(f\"\\n‚úÖ Saved: {ml_path.name}\")\n",
    "    print(f\"   Shape: {ml_matrix.shape}\")\n",
    "    \n",
    "    # List all saved files\n",
    "    print(f\"\\nüìÅ All files in {DATA_PROCESSED.name}/:\")\n",
    "    for f in DATA_PROCESSED.iterdir():\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f\"   {f.name}: {size_kb:.1f} KB\")\n",
    "\n",
    "print(\"\\n‚úÖ Cell 12 complete. Ready for Cell 13 (Final Checkpoint).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Final Checkpoint Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéØ FINAL CHECKPOINT SUMMARY - GSE114007 DATA INGESTION\n",
      "======================================================================\n",
      "\n",
      "‚úÖ DATA INGESTION COMPLETE\n",
      "\n",
      "üìä DATASET METRICS:\n",
      "   Samples (n_samples): 38\n",
      "   Genes (n_genes): 23710\n",
      "\n",
      "üìã CLASS DISTRIBUTION:\n",
      "   OA: 20\n",
      "   Control: 18\n",
      "\n",
      "üß¨ EXAMPLE GENES (first 5 in index):\n",
      "   1. FN1 (mean expression: 15.97)\n",
      "   2. COMP (mean expression: 13.41)\n",
      "   3. MALAT1 (mean expression: 14.67)\n",
      "   4. CHI3L2 (mean expression: 9.84)\n",
      "   5. CLU (mean expression: 14.22)\n",
      "\n",
      "üìÅ OUTPUT FILES:\n",
      "   1. C:\\Users\\povan\\Kairos_Therapeutics\\data\\processed/GSE114007_metadata.csv\n",
      "   2. C:\\Users\\povan\\Kairos_Therapeutics\\data\\processed/GSE114007_raw_source_matrix.csv\n",
      "   3. C:\\Users\\povan\\Kairos_Therapeutics\\data\\processed/GSE114007_ml_matrix.csv\n",
      "\n",
      "‚úÖ VALIDATION CHECKS:\n",
      "   - Samples match metadata: True\n",
      "   - No all-NaN genes: True\n",
      "   - ML matrix mean ~0: True\n",
      "\n",
      "======================================================================\n",
      "üöÄ NEXT NOTEBOOK: 02_QC_and_EDA.ipynb\n",
      "   - PCA visualization\n",
      "   - Sample QC (detect outliers)\n",
      "   - Gene expression distributions\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL 13: FINAL CHECKPOINT SUMMARY\n",
    "=================================\n",
    "Print comprehensive summary of what was loaded.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üéØ FINAL CHECKPOINT SUMMARY - GSE114007 DATA INGESTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if expression_df is None or expression_df.empty:\n",
    "    print(\"\\n‚ùå DATA INGESTION INCOMPLETE\")\n",
    "    print(\"\\nüìã Status:\")\n",
    "    print(\"   - Metadata: ‚úÖ Loaded\")\n",
    "    print(\"   - Expression: ‚ùå Failed to load\")\n",
    "    print(\"\\nüîß NEXT STEPS:\")\n",
    "    print(\"   1. Check files in data/raw/GSE114007/\")\n",
    "    print(\"   2. Open the largest file manually\")\n",
    "    print(\"   3. Report the file format to continue\")\n",
    "    print(f\"\\nüìÅ Files downloaded:\")\n",
    "    for f in DATA_RAW.iterdir():\n",
    "        size_mb = f.stat().st_size / (1024*1024)\n",
    "        print(f\"   - {f.name} ({size_mb:.2f} MB)\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ DATA INGESTION COMPLETE\")\n",
    "    \n",
    "    print(\"\\nüìä DATASET METRICS:\")\n",
    "    print(f\"   Samples (n_samples): {raw_source_matrix.shape[1]}\")\n",
    "    print(f\"   Genes (n_genes): {raw_source_matrix.shape[0]}\")\n",
    "    \n",
    "    if 'condition' in metadata_df.columns:\n",
    "        print(f\"\\nüìã CLASS DISTRIBUTION:\")\n",
    "        for cond, count in metadata_df['condition'].value_counts().items():\n",
    "            print(f\"   {cond}: {count}\")\n",
    "    \n",
    "    print(f\"\\nüß¨ EXAMPLE GENES (first 5 in index):\")\n",
    "    for i, gene in enumerate(raw_source_matrix.index[:5], 1):\n",
    "        mean_expr = raw_source_matrix.loc[gene].mean()\n",
    "        print(f\"   {i}. {gene} (mean expression: {mean_expr:.2f})\")\n",
    "    \n",
    "    print(f\"\\nüìÅ OUTPUT FILES:\")\n",
    "    print(f\"   1. {DATA_PROCESSED}/GSE114007_metadata.csv\")\n",
    "    print(f\"   2. {DATA_PROCESSED}/GSE114007_raw_source_matrix.csv\")\n",
    "    print(f\"   3. {DATA_PROCESSED}/GSE114007_ml_matrix.csv\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ VALIDATION CHECKS:\")\n",
    "    print(f\"   - Samples match metadata: {raw_source_matrix.shape[1] == len(metadata_df)}\")\n",
    "    print(f\"   - No all-NaN genes: {not raw_source_matrix.isna().all(axis=1).any()}\")\n",
    "    print(f\"   - ML matrix mean ~0: {abs(ml_matrix.values.mean()) < 0.01}\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ NEXT NOTEBOOK: 02_QC_and_EDA.ipynb\")\n",
    "print(\"   - PCA visualization\")\n",
    "print(\"   - Sample QC (detect outliers)\")\n",
    "print(\"   - Gene expression distributions\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting Section\n",
    "\n",
    "If the notebook didn't successfully load expression data, run the cell below to get diagnostic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TROUBLESHOOTING CELL: Manual File Inspection\n",
    "============================================\n",
    "Run this if automatic parsing failed.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîß TROUBLESHOOTING: Manual File Inspection\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìÅ Files in data/raw/GSE114007/:\")\n",
    "for f in sorted(DATA_RAW.iterdir()):\n",
    "    size_mb = f.stat().st_size / (1024*1024)\n",
    "    print(f\"\\n   üìÑ {f.name}\")\n",
    "    print(f\"      Size: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Try to peek at first few lines\n",
    "    try:\n",
    "        if f.name.endswith('.gz'):\n",
    "            with gzip.open(f, 'rt') as file:\n",
    "                lines = [file.readline() for _ in range(5)]\n",
    "        else:\n",
    "            with open(f, 'r') as file:\n",
    "                lines = [file.readline() for _ in range(5)]\n",
    "        \n",
    "        print(f\"      First 3 lines:\")\n",
    "        for i, line in enumerate(lines[:3]):\n",
    "            # Truncate long lines\n",
    "            display_line = line.strip()[:100]\n",
    "            if len(line.strip()) > 100:\n",
    "                display_line += \"...\"\n",
    "            print(f\"         {i+1}: {display_line}\")\n",
    "    except Exception as e:\n",
    "        print(f\"      Could not read: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìù INSTRUCTIONS:\")\n",
    "print(\"   1. Look at the file with largest size\")\n",
    "print(\"   2. Note if it's tab-separated, comma-separated, or space-separated\")\n",
    "print(\"   3. Note if first column is gene IDs or if there's a header row\")\n",
    "print(\"   4. Report this to Claude for custom parsing code\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
